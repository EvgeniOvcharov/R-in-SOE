---
title: "Classification"
author: "Elara"
date: "2016年5月20日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# logistic regression   
$$p(Y=1|X)=\beta_0+\beta_{1}X$$
左边0-1右边不一定0-1,不好       
$$
logit(p)=log(\frac{p}{1-p})=log(\Omega)=\beta_0+\beta_{1}X
$$
左边变成负无穷到正无穷,可以使用,左边叫做对数发生比         
其中$p=u_Y$是Y的条件均值(即给定X的取值,Y=1的概率)                              
$$
p(X)=\frac{exp(\beta_0+\beta_{1}X)}{(1+exp(\beta_0+\beta_{1}X))}
$$      

## example
```{r}
library("faraway")
data(pima, package="faraway")
head(pima)
b <- factor(pima$test)
head(b)
#模型构建(训练)
#family,二元,link,logit->二元logit模型
m <- glm(b ~ diastolic + bmi, family=binomial(link="logit"), data=pima)
summary(m)
#系数代表的是X变化对与对数发生比的影响
#只用bmi回归因为diastolic不显著,binomial默认是logit不写也行
m.red <- glm(b ~ bmi, family=binomial, data=pima)
summary(m.red)
#预测
#1 求p(X) Y=1的概率(bmi=32,输入需要用data.frame)
newdata <- data.frame(bmi=32.0)
#type用response,出来的结果是p(x),给定X,Y=1的概率
predict(m.red, type="response", newdata=newdata)
#2 验证p(X)结果正确
E<-exp(-3.68641+0.09353*32)
E/(1+E)
# According to this model, the probability is about 33.3%. The same calculation for someone in the 90th percentile gives a probability of 54.9%
# 选择bmi的90%分位数(41.5)
newdata <- data.frame(bmi=quantile(pima$bmi, .90))
predict(m.red, type="response", newdata=newdata)

```

#exercise
```{r}
SoftDrink<-read.table(file="C:\\Users\\44180\\Documents\\R-in-SOE\\R\\R-class\\c12\\data\\SoftDrink.txt",header=TRUE)
head(SoftDrink)
SoftDrink$Choice<-as.factor(SoftDrink$Choice)
#去掉品牌
Fit<-glm(Choice~.-Brand,data=SoftDrink,family=binomial(link="logit"))
summary(Fit)
#只留下calories和fruits
Fit<-glm(Choice~.-Brand-Price-Fat-Age-Vitamin,data=SoftDrink,family=binomial(link="logit"))
summary(Fit)
coef(Fit)
#卡路里提高一单位,可以让对数发生比平均减少0.017单位
exp(coef(Fit))
#卡路里提高一单位,可以让发生比(优势比或购买意向)变成原来的0.9830543
```

# cluster analysis       
##Hierarchical Clustering       
系统聚类 层次聚类,点之间用欧式距离               
![](C:\Users\44180\Documents\R-in-SOE\R\R-class\c12\1.png)    

###Interpreting a Dendrogram    
![](C:\Users\44180\Documents\R-in-SOE\R\R-class\c12\2.png)    

分类的类数不同          
![](C:\Users\44180\Documents\R-in-SOE\R\R-class\c12\3.png)    
###Linkage (distance) between Cluster Pairs                   
类间距离
1. Nearest neighbor (single linkage).最小距离法         
If you use the nearest neighbor method to form clusters, the distance between two clusters is defined
as the smallest distance between two cases in the different clusters.           
2个类中距离最近的元素的距离作为类间距离         
2. Furthest neighbor (complete linkage).最大距离法              
If you use a method called furthest neighbor (also known as complete linkage), the distance between
two clusters is defined as the distance between the two furthest points.                
2个类中距离最远的元素的距离作为类间距离                 
3. Average method.平均法                
Mean intercluster dissimilarity. Compute all pairwise dissimilarities between the observations in cluster
A and the observations in cluster B, and record the average of these dissimilarities.           
计算2个类中所有点组合的距离,取平均              
4. Centroid method.中心法     
This method calculates the distance between two clusters as the sum of distances between cluster
means for all of the variables. In the centroid method, the centroid of a merged cluster is a weighted
combination of the centroids of the two individual clusters, where the weights are proportional to the
sizes of the clusters. One disadvantage of the centroid method is that the distance at which clusters
are combined can actually decrease from one step to the next. This is an undesirable property because
clusters merged at later stages are more dissimilar than those merged at early stages.                  
计算各个类中各个变量的均值,用这些均值在不同类之间的距离和作为类间距离.已经合并的类用他们的均衡根据类大小加权均值作为合并类的均值.       
缺点:距离随着类越来越大会缩减.          

###example
```{r}
# 1
#Calculate
x<-c(1,2,6,8,11); dim(x)<-c(5,1)
d<-dist(x)
hc1<-hclust(d, "single"); hc2<-hclust(d, "complete")
hc3<-hclust(d, "median"); hc4<-hclust(d, "mcquitty")
#Plot
opar <- par(mfrow = c(2, 2))
plot(hc1,hang=-1); plot(hc2,hang=-1)
plot(hc3,hang=-1); plot(hc4,hang=-1)
par(opar)

# 2 
#各省数据
PoData<-read.table(file="C:\\Users\\44180\\Documents\\R-in-SOE\\R\\R-class\\c12\\data\\PollutionData1.txt",header=TRUE)
#只拿数据部分
CluData<-PoData[,2:7]
head(CluData)
###Hierarchical Clustering层次聚类
#计算欧式距离矩阵
DisMatrix<-dist(CluData,method = "euclidean")#欧式距离
DisMatrix
#用ward.D方法聚类
CluR<-hclust(d=DisMatrix,method="ward.D")
#Graph_1
plot(CluR,labels=PoData[,1])
box()#图加框
#Graph_2 类内距离与剩余类数的关系.例如类内距离200左右,归为3类,差值代表再多合并一次(减少一类)所要增加的类内距离.
plot(CluR$height,30:1,type="b",cex=0.7,xlab="Distance",ylab="Number of Cluster",main="Scree Plot")


```
