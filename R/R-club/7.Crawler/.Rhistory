install.packages("parallel")
library(R2SWF)
if (capabilities("cairo")) {
olddir = setwd(tempdir())
svg("Rplot%03d.svg", onefile = FALSE)
set.seed(123)
x = rnorm(5)
y = rnorm(5)
for (i in 1:100) {
plot(x <- x + 0.1 * rnorm(5), y <- y + 0.1 * rnorm(5), xlim = c(-3,
3), ylim = c(-3, 3), col = "steelblue", pch = 16, cex = 2, xlab = "x",
ylab = "y")
}
dev.off()
output = svg2swf(sprintf("Rplot%03d.svg", 1:100), interval = 0.1)
swf2html(output)
setwd(olddir)
}
library(ggmap)
library(mapproj)
map <- get_map(location = 'China', zoom = 4)
ggmap(map)
map <- get_map(location = 'Beijing', zoom = 10, maptype = 'roadmap')
ggmap(map)
install.packages("knitr")
install.packages("R2SWF")
install.packages("ggmap")
install.packages("mapproj")
install.packages("animation")
install.packages("maps")
dir(getwd())
memory.size()
memory.limit()
ls()
ls(getwd)
help(ls)
x<-1
ls
ls()
objects()
object.size()
object.size(x)
calling objects("package:base")
objects("package:base")
search()
help(rm)
history(#)
help(history)
6
help("history")
history(4)
library()
search('')
search()
library(knitr)
search()
help("help.start")
help.start
help.start()
help(rep)
rep(1:4,2)
pmin(c(1,2,3),c(2,3))
pmin(c(1,2,3),c(2,3,4))
nlm(function(x) return(x^2-sin(x)),8)
help(nlm)
rep
help(rep)
help("cbind")
help(runif)
runif(20)
summary(x)
x <- runif(20)
summary(x)
hist(x)
install.packages("ggpolt")
install.packages("ggplot")
library(ggplot2)
set.seed (1)
m <- 10000
n <-  5000
A <- matrix (runif (m*n),m,n)
# Matrix multiply
system.time (B <- crossprod(A))
# Cholesky Factorization
system.time (C <- chol(B))
# Singular Value Decomposition
m <- 10000
n <- 2000
A <- matrix (runif (m*n),m,n)
system.time (S <- svd (A,nu=0,nv=0))
# Principal Components Analysis
m <- 10000
n <- 2000
A <- matrix (runif (m*n),m,n)
system.time (P <- prcomp(A))
# Linear Discriminant Analysis
library('MASS')
g <- 5
k <- round (m/2)
A <- data.frame (A, fac=sample (LETTERS[1:g],m,replace=TRUE))
train <- sample(1:m, k)
system.time (L <- lda(fac ~., data=A, prior=rep(1,g)/g, subset=train))
.libPaths()
plot
install.packages("stringr")
library(stringr)
str_extract_all(string = c("regular.expressions\n","\n"), pattern =".")
test_vector2<-c("AlphaGo实在厉害！","alphago是啥","阿尔法狗是一条很凶猛的狗。") str_extract_all(string = test_vector2, pattern ="AlphaGo|阿尔法狗")
test_vector2<-c("AlphaGo实在厉害！","alphago是啥","阿尔法狗是一条很凶猛的狗。")
str_extract_all(string = test_vector2, pattern ="AlphaGo|阿尔法狗")
str_extract_all(string = c("abc","ac","bc"),pattern = "ab?c")
str_extract_all(string = c("abababab","abc","ac"),pattern = "(ab)*")
str_extract_all(string = c("abababa","abc","acb"),pattern = "(ab)*")
str_extract_all(string = c("ababcaba","abc","ab"),pattern = "(ab)*")
str_extract_all(string = c("ababcabab","abc","ac"),pattern = "(ab)+")
str_extract_all(string = c("ababcaba","abc","ab"),pattern = "(ab)+")
str_extract_all(string = c("abababab","ababc","abc"),pattern = "(ab){2,3}")
str_extract_all(string = c("abababab","ababc","abc"),pattern = "(ab){2,4}")
str_extract_all(string = c("ababababab","ababc","abc"),pattern = "(ab){2,4}")
str_extract_all(string = c("ababababab","ababc","abc"),pattern = "(ab){2,3}")
str_extract_all(string = c("abababab","ababc","abc"),pattern = "(ab){2,4}")
str_extract_all(string = c("ababcabab","ababc","abc"),pattern = "(ab){2,4}")
strsplit(x="strsplit.aslo.uses.regular.expressions", split=".")
strsplit(x="strsplit.aslo.uses.regular.expressions", split="\\.")
strsplit(x="strsplit.aslo.uses./nregular.expressions", split=".")
strsplit(x="strsplit.aslo.uses.\nregular.expressions", split=".")
strsplit(x="strsplit.aslo.uses.\n.regular.expressions", split=".")
strsplit(x="s\n.trsplit.aslo.uses.regular.expressions", split=".")
x<- c("I love R","I'm fascinated by Statisitcs")
View(x)
nchar(x)
str_count(x,pattern = "")
str_length(x)
DNA <- "AgCTaaGGGcctTagct
DNA <- "AgCTaaGGGcctTagct"
tolower(DNA)
chartr("T", "U", DNA)
install.packages("checkenc")
install.packages("checkenc")
help(checkenc)
help("checkenc)
help("checkenc")
install.packages("dplyr")
library(dplyr)
url <-'http://movie.douban.com/top250?format=text'
web <- readLines(url,encoding="UTF-8")
name<-str_extract_all(string = web, pattern = '<span class="title">.+</span>')
View(name)
head(name)
movie.names_line <- unlist(name)
head(movie.names_line)
movie.names <- str_extract(string = movie.names_line, pattern = ">[^&].+<") %>% str_replace_all(string = ., pattern = ">|<",replacement = "")
movie.names<- na.omit(movie.names)
paste("control",1:3,sep = "_")
paste("control","_")
text <- "I love R.\nI'm fascinated by Statisitcs."
cat(text)
help("cat")
strsplit(text,split = " ")
strsplit(text,split = "\\s")
strsplit(text,split = "\s")
strsplit(text,split = \s)
strsplit(text,split = "\\s")
x<- c("I love R","I'm fascinated by Statisitcs","I")
x<- c("I love R","I'm fascinated by Statisitcs","I")
grep(pattern = "love",x = x)
grep(pattern = "love",x = x,value = TRUE
grep(pattern = "love",x = x,value = TRUE)
grepl(pattern = "love",x = x)
str_detect(string = x, pattern = "love")
match(x = "I",table = x)
test_vector3<-c("Without the vowels,We can still read the word.")
sub(pattern = "[aeiou]",replacement = "-",x = test_vector3)
gsub(pattern = "[aeiou]",replacement = "-",x = test_vector3)
str_replace_all(string = test_vector3,pattern = "[aeiou]",replacement = "")
substr("abcdef", start = 2, stop = 4)
substring("abcdef", first = 1:6, last = 1:6)
str_sub("abcdef",start = 2, end = 4)
str_sub("abcdef",start = 1:6, end = 1:6)
text_weibo<- c("#围棋人机大战# 【人工智能攻克围棋 AlphaGo三比零完胜李世石】","谷歌人工智 能AlphaGo与韩国棋手李世石今日进行了第三场较量","最终AlphaGo战胜李世石，连续取得三场胜 利。接下来两场将沦为李世石的“荣誉之战。")
str_match_all(text_weibo,pattern = "#.+#")
str_match_all(text_weibo, pattern = "[a-zA-Z]+")
strtrim(c("abcde", "abcde", "abcde"),width =  c(1, 5, 10))
str_pad(string = c("abcde", "abcde", "abcde"),width =  c(1, 5, 10),side = "right")
string <- "Each character string in the input is first split into\n paragraphs (or lines containing whitespace only). The paragraphs are then formatted by breaking lines at word boundaries."
strwrap(x = string, width = 30
strwrap(x = string, width = 30)
cat(str_wrap(string = string, width = 30))
help(sapply)
x <- list(1,2,3,4,5,6,7,8,9)
head(x)
y <- sapply(x,x-1)
y <- sapply(x,mean)
y
y <- sapply(x,x <- x-1)
y <- sapply(x,[x-1])
y <- sapply(x,x[-1])
y <- sapply(x,x[]-1)
y <- sapply(x,FUN=function(x) x-1)
y
install.packages("jiebaR")
library("jiebaR")
keys = worker("keywords", topn = 1)
keys <= "我爱北京天安门"
keys <= "一个文件路径.txt"
install.packages("tm")
help(while)
help("while")
exc <- function(n){
{isInt<-function(n){
if(mode(n)=="numeric")
{
if(n%%1==0) return(TRUE)
else return(FALSE)
}
else return(FALSE)
}
}
{if(!isInt(n)|n <= 0) {
print("要求输入正整数")
}else{
{While(n!=1)
{
If(n%%2=0)
{
n <- n/2
}else{
n <- 3*n+1
}
}
}
print(“运算成功”)
}
}
}
exc(1)
exc <- function(n){
{isInt<-function(n){
if(mode(n)=="numeric")
{
if(n%%1==0) return(TRUE)
else return(FALSE)
}
else return(FALSE)
}
}
{if(!isInt(n)|n <= 0) {
print("要求输入正整数")
}else{
{While(n!=1)
{
if(n%%2==0) {
n <- n/2
}else {n <- 3*n+1}
}
}
print("运算成功")
}
}
}
exc(0.1)
exc(-1)
exc(0)
exc(1)
exc <- function(n){
{isInt<-function(n){
if(mode(n)=="numeric")
{
if(n%%1==0) return(TRUE)
else return(FALSE)
}
else return(FALSE)
}
}
{if(!isInt(n)|n <= 0) {
print("要求输入正整数")
}else{
{while(n!=1)
{
if(n%%2==0) {
n <- n/2
}else {n <- 3*n+1}
}
}
print("运算成功")
}
}
}
exc(1)
exc(2)
exc(3)
is.integer(3)
homework0325 <- function(n){
{#判断是不是整数。输入数据默认是double，is.integer不好用#
isInt<-function(n){
if(mode(n)=="numeric")
{
if(n%%1==0) return(TRUE)
else return(FALSE)
}
else return(FALSE)
}
}
{if(!isInt(n)|n <= 0) {
print("要求输入正整数")
}else{
{while(n!=1) {
if(n%%2==0) {
n <- n/2
}else {n <- 3*n+1}
}
}
print("运算成功")
}
}
}
homework0325(4.6)
homework0325(-4)
homework0325(0)
homework0325 <- function(n){
{#判断是不是整数。输入数据默认是double，is.integer不好用#
isInt<-function(n){
if(mode(n)=="numeric")
{
if(n%%1==0) return(TRUE)
else return(FALSE)
}
else return(FALSE)
}
}
{if(!isInt(n)|n <= 0) {
print("要求输入一个正整数")
}else{
{while(n!=1) {
if(n%%2==0) {
n <- n/2
}else {n <- 3*n+1}
}
}
print("运算成功")
}
}
}
homework0325(1000)
homework0325(1001)
n
library(rvest)
install.packages("rvest")
library(rvest)
library(RCurl)
setwd("~/soe/R/7.Crawler")
library(rvest)
%%R
library(rvest)
# vignette("selectorgadget")
lego_movie <- read_html("http://www.imdb.com/title/tt1490017/")
%%R
rating <- lego_movie %>%
html_nodes("strong span") %>%
html_text() %>%
as.numeric()
rating
cast <- lego_movie %>%
#提取
html_nodes("#titleCast .itemprop span") %>%
html_text()
cast
poster <- lego_movie %>%
html_nodes(xpath="//div[@class='poster']/a/img") %>%
html_attr("src")
poster
poster <- lego_movie %>%
#没有说明则使用css。需要xpath需要说明。
#格式//div[@属性名='属性值'] /下一级节点名/下一级节点名
html_nodes(xpath="//div[@class='slate']/a/img") %>%
html_attr("src")
poster
DoubanUrl <- 'http://movie.douban.com/top250'
PageUrlList <- read_html(DoubanUrl) %>%
#提取div节点中所有class是paginator的节点里面的a里面的东西
html_nodes(xpath = "//div[@class='paginator']/a") %>%
#进一步提取属性href里面的超链接的内容
html_attr("href")
PageUrlList <- read_html(DoubanUrl) %>%
#提取div节点中所有class是paginator的节点里面的a里面的东西
html_nodes(xpath = "//div[@class='paginator']/a") %>%
#进一步提取属性href里面的超链接的内容
html_attr("href") %>%
#超链接的内容是接在主网址后面，所以要paste链接起来，最后合并成向量
str_c(DoubanUrl, ., sep="") %>% c(DoubanUrl,.)
library(RCurl)
library(rvest)
library(stringr)
library(plyr)
library(dplyr)
DoubanUrl <- 'http://movie.douban.com/top250'
PageUrlList <- read_html(DoubanUrl) %>%
#提取div节点中所有class是paginator的节点里面的a里面的东西
html_nodes(xpath = "//div[@class='paginator']/a") %>%
#进一步提取属性href里面的超链接的内容
html_attr("href") %>%
#超链接的内容是接在主网址后面，所以要paste链接起来，最后合并成向量
str_c(DoubanUrl, ., sep="") %>% c(DoubanUrl,.)
MovieUrl <-  NULL
for (url in PageUrlList) {
item = read_html(url) %>%
#读取div节点中满足class是hd的节点中的a节点里面的@href属性内容
html_nodes(xpath="//div[@class='hd']/a/@href") %>%
#提取出所得字符串的https[\\S]和[\\d]{7}之间内容
str_extract('https[\\S]+[\\d]{7}')
#循环成向量
MovieUrl = c(MovieUrl, item)
}
head(MovieUrl)
url <- "https://api.douban.com/v2/movie/1292052"
result <- read_html(url)
result
